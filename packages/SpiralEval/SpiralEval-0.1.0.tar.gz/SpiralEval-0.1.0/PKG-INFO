Metadata-Version: 2.1
Name: SpiralEval
Version: 0.1.0
Summary: Evaluation for characteristics
Home-page: https://github.com/Spiral-AI/SpiralEval
Author: Kosei Uemura
Author-email: koseiuemura1227@gmail.com
Keywords: openai,api,evaluation,characteristics,gpt
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Requires-Python: >=3.8, <4
Description-Content-Type: text/markdown
License-File: LICENSE

# SpiralEval ðŸŒ€
## Introduction ðŸš€
The primary purpose of SpiralEval is to establish an evaluation method based on character traits.
SpiralEval enables us to elaborate a better character.

Here are the main functionalities:

- From the conversation of the target person, we create a summary of that person's character traits.
- Evaluation of SpiralEval based on the evaluation dataset derived from the character trait summary.
- Determine the number of sentences in the text generated by LLM that effectively express character traits.

## Installation ðŸ”§

The easiest way to install SpiralFilm is simply by using pip:
```
pip install spiraleval
```

Magic! ðŸŽ©âœ¨

## Tutorial ðŸ“š

Now that you've got SpiralEval installed, let's see it in action! 
We need to follow the following process to get evaluation for your LLM.

### Step 1: Generate the summary of your character
For this, we'll use the script in `examples/simple_example.py`

```python
from SpiralEval.spiraleval import EvalSummary

# First things first, let's set up the path for files
api_path = "your_openai_api_key_path.txt"
reference_path = 'your_reference_dataset.json'

# Now, let's create and run a EvalSummary instance
f = EvalSummary(
    api_path, reference_path).run()

# Booom, you should get character summary on the same directory, named character_summary.txt
```

### Step 2: Just try our evaluation. ðŸª„
Evaluating your LLM with use of a number of QA takes API cost.
Before your operation, you can try our evaluation on a simple QA.

```python
from SpiralEval.spiraleval import EvalLLMTrial

# Let's set up path for files
api_path = "your_openai_api_key_path.txt"
summary_path = "your_generated_summary.txt"
reference_path = 'your_reference_dataset.json'

# Now, let's create a EvalLLMTrial instance with the specified path.
eval_llm_trial = EvalLLMTrial(api_path, summary_path, reference_path)
# You can get the character summary here and use it for the following prompt.
character_summary = eval_llm_trial.character_summary

instruction = f"""You will determine if the target sentence I provide is either 
generated by a language model (False) or belongs to the set of reference sentences (True), 
based on True or False criteria.
Both the reference and target sentences come as pairs of questions and 
their answers. The following is the summary of his/her character. {character_summary}"""

eval_llm_trial.run(instruction)
# You will be asked to provide question and answer for this prompt.
```
In this example, the run_parallel method allows for concurrent processing of multiple prompts, drastically reducing the time it would take if done sequentially. This is especially handy for batch processing or when dealing with real-time requirements.

### Example 3: Use our evaluation on your LLM ðŸ§ 
There's immense power in context, and with `FilmCore`, you can harness this power seamlessly. This example, which you can find in `examples/conversation_example.py`, showcases how you can retain context and query it in subsequent interactions:


By using the create_from method, we can ensure a smooth continuation of the conversation. So, whether it's a fact, a story detail, or a crucial piece of data, FilmCore helps keep the narrative threads intact. ðŸ§µðŸ“–
```python
from SpiralEval.spiraleval import EvalLLM

# Let's set up path for files
api_path = "your_openai_api_key_path.txt"
summary_path = "your_generated_summary.txt"
# Paste your answers generated by LLM on the following file.
target_path = "your_target_dataset.json"
reference_path = 'your_reference_dataset.json'

eval_llm = EvalLLM(api_path, summary_path, target_path, reference_path)
character_summary = eval_llm.character_summary

instruction = f"""You will determine if the target sentence I provide is either 
generated by a language model (False) or belongs to the set of reference sentences (True), 
based on True or False criteria.
Both the reference and target sentences come as pairs of questions and 
their answers. The following is the summary of his/her character. {character_summary}"""

eval_llm.run(instruction)
```


### Additional Example: Test our evaluation system ðŸŒŠ
If you are doubt about our evaluation system. You can test it!
```python
from SpiralEval.spiraleval import EvalSpiralEval

# Let's set up path for files
api_path = "your_openai_api_key_path.txt"
summary_path = "your_generated_summary.txt"
target_path = "your_target_dataset.json"
reference_path = 'your_reference_dataset.json'

evalspiraleval = EvalSpiralEval(api_path, summary_path, target_path, reference_path)
character_summary = evalspiraleval.character_summary

instruction = f"""You will determine if the target sentence I provide is either 
generated by a language model (False) or belongs to the set of reference sentences (True), 
based on True or False criteria.
Both the reference and target sentences come as pairs of questions and 
their answers. The following is the summary of his/her character. {character_summary}"""

evalspiraleval.run(instruction)
```

With this, you can evaluate your LLM based on characteristics traits.

And that's it, folks! You're now ready to start making your own epic conversational masterpieces with SpiralEval! Happy coding! ðŸ’»ðŸš€

But wait, there's more! Be sure to check out the "examples" folder for more usage scenarios and ideas. We've packed it full of tips, tricks, and goodies to get you up and running in no time. ðŸ“šðŸ”

## Contribution ðŸ¤

If you feel like giving back, we always welcome contributions. But remember, at SpiralEval, we're all about keeping it simple and transparent. We love that you're excited to add features
